@startuml

!pragma horizontalLineBetweenDifferentPackageAllowed

note top of beam_client: The client might be code in any Beam SDK (not just Java)
rectangle "Beam Client" as beam_client {
    artifact "Beam Client SDK    " {
        rectangle "Client Code" as beam_client_code
    }
}

rectangle "Flink Client JVM" as flink_client {
    artifact "Flink Runner Jar" as runner_jar {
        rectangle "gRPC Server" as job_server {
            rectangle "Job API (JobService)" as job_service
            rectangle "Artifact API (ArtifactStagingService)" as artifact_staging
        }
    }
    note top of runner_jar: A new Flink ExecutionEnvironment is spawned for each job.
    note bottom of runner_jar: The runner jar is submitted to Flink out-of-band.\nThis starts the Job API.
}

node "Flink Worker Node" {
    rectangle "Flink TaskManager JVM" as flink_task {
        artifact "Flink Runner Jar" {
            rectangle "Harness Manager" as harness_manager {
                rectangle "gRPC Server" {
                    rectangle "Control and Data Planes" as control_plane
                    rectangle "Auxiliary Services" as other_grpc
                }
            }
            rectangle "Fused Stage Operator" as operator
        }
    }
    rectangle "Docker" as docker {
        artifact "SDK Harness (Environment)" {
            rectangle "Boot Code and Fn Execution" as fn_execution
        }
    }
}

beam_client_code -down-> job_service: Run
beam_client_code --> artifact_staging: Put Artifact

harness_manager --> docker: Create Environment

job_service -down-> operator: Execute

operator -> harness_manager

fn_execution <-> control_plane
fn_execution --> other_grpc

@enduml
